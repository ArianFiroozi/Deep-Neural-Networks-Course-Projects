{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "path=kagglehub.dataset_download(\"mohamad1dehqani/persian-spam-email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data=pd.read_csv('./data/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_counts = raw_data['label'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.title('Number of Instances per Class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ﻿ممنون آقا سامان.\\nمن پارسال اصلا آزاد شرکت نک...\n",
       "1      ﻿سلام آقای کریمی\\nبالاخره آزمونارشد تموم شد من...\n",
       "2      ﻿درود بر حاج وحیدی بنده بعنوان یک دکتری تاریخ ...\n",
       "3      ﻿با سلام  و احترام\\nضمن تقدیر از مسولین محترم ...\n",
       "4      ﻿با سلام اینجانب یک دستگاه خودرو پراید 131 با ...\n",
       "                             ...                        \n",
       "995    ﻿\\nبسمه تعالی\\n\\nسازمان زیباسازی شهرداری استان...\n",
       "996    ﻿\\n\\nبه مناسبت فرا رسیدن میلاد دخت پیامبر گرام...\n",
       "997    ﻿\\nدرود هموطن من\\n\\n \\n\\nتست رایگان   \\n\\n    ...\n",
       "998    ﻿\\n\\n    *درج **لینک  در 8700 وبلاگ\\n    *\\n\\n...\n",
       "999    ﻿\\nسلام به دوستان عزیز\\nشما هم میتوانید از این...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url_pattern = r'http[s]?://\\S+|www\\.\\S+|WWW\\.\\S+|Www\\.\\S+|WwW\\.\\S+'\n",
    "email_pattern = r'\\b[A-Za-z0-9\\*._%+-]+@[A-Za-z0-9\\*.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "phone_pattern = r'\\d{11}|(\\d{4}[ -\\*]\\d{3}[ -\\*]\\d{4})|\\d{3}[-]+\\d{8}|\\d{3}[ ]+\\d{8}|[(]\\d{3}[) ]+\\d{8}|\\d{8}'\n",
    "combined_pattern = f'({url_pattern})|({email_pattern})|({phone_pattern})'\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    return re.sub(combined_pattern, '', cleaned_text)\n",
    "\n",
    "\n",
    "raw_data['text'] = raw_data['text'].apply(clean_text)\n",
    "\n",
    "raw_data.to_csv('./data/cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/persian_stopwords', 'r', encoding='utf-8') as f:\n",
    "    persian_stop_words = f.read().splitlines()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in persian_stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "raw_data['text'] = raw_data['text'].apply(remove_stopwords)\n",
    "raw_data.to_csv('./data/cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "model = AutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
    "\n",
    "texts = raw_data['text'].tolist()\n",
    "inputs = tokenizer(texts, padding='max_length', max_length=32, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "hidden_states = outputs.last_hidden_state\n",
    "sentence_vectors = hidden_states.mean(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=120)\n",
    "reduced_vectors = pca.fit_transform(sentence_vectors)\n",
    "\n",
    "vectorized_data = pd.DataFrame(reduced_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_data['label'].values.copy()\n",
    "for i in range(len(labels)):\n",
    "    if labels[i]=='ham':\n",
    "        labels[i]=0\n",
    "    else:\n",
    "        labels[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 120)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sequence_length = 1\n",
    "num_samples = vectorized_data.shape[0]\n",
    "num_features = vectorized_data.shape[1]\n",
    "\n",
    "num_sequences = num_samples // sequence_length\n",
    "\n",
    "# data_reshaped = vectorized_data[:num_sequences * sequence_length].to_numpy().reshape(num_sequences, sequence_length, num_features)\n",
    "\n",
    "labels_reshaped = labels[:num_sequences * sequence_length].reshape(num_sequences, sequence_length)\n",
    "labels_reshaped = labels_reshaped[:, -1] \n",
    "\n",
    "print(vectorized_data.shape)\n",
    "print(labels_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, labels_reshaped, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_134\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_134\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">384,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_105               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1888</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,889</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_100 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m384,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_103 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_105               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_64 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1888\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_134 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,889\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,065</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m392,065\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,065</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m392,065\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Embedding(input_dim=6000, output_dim=64,embeddings_initializer='uniform'),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(152, 64)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_model.build(input_shape=(None, 120))\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5129 - loss: 0.6931 - val_accuracy: 0.6714 - val_loss: 0.6850\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7071 - loss: 0.6812 - val_accuracy: 0.8857 - val_loss: 0.6591\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8465 - loss: 0.6504 - val_accuracy: 0.8857 - val_loss: 0.5873\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8640 - loss: 0.5712 - val_accuracy: 0.8857 - val_loss: 0.4520\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8748 - loss: 0.4439 - val_accuracy: 0.9143 - val_loss: 0.3295\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9011 - loss: 0.3247 - val_accuracy: 0.9143 - val_loss: 0.2519\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2626 - val_accuracy: 0.9429 - val_loss: 0.2034\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9260 - loss: 0.2208 - val_accuracy: 0.9571 - val_loss: 0.1659\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9552 - loss: 0.1622 - val_accuracy: 0.9571 - val_loss: 0.1380\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.1309 - val_accuracy: 0.9571 - val_loss: 0.1146\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9055 - loss: 0.2265 \n",
      "Test Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_train[:len(X_train)//5], y_train[:len(y_train)//5]))\n",
    "\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_139\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_139\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_105 (\u001b[38;5;33mEmbedding\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_74 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_75 (\u001b[38;5;33mLSTM\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout\n",
    "\n",
    "# lstm_model = Sequential([\n",
    "#     Embedding(input_dim=6000, output_dim=64),\n",
    "#     LSTM(64, dropout=0.2),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# lstm_model.build(input_shape=(None, 120))\n",
    "# lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# lstm_model.summary()\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=6000, output_dim=64),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.4699 - loss: 0.6946 - val_accuracy: 0.4357 - val_loss: 0.6955\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5291 - loss: 0.6926 - val_accuracy: 0.4357 - val_loss: 0.6979\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5320 - loss: 0.6916 - val_accuracy: 0.4357 - val_loss: 0.6956\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.4977 - loss: 0.6934 - val_accuracy: 0.4357 - val_loss: 0.6968\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5218 - loss: 0.6926 - val_accuracy: 0.4357 - val_loss: 0.6977\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5237 - loss: 0.6925 - val_accuracy: 0.4357 - val_loss: 0.6951\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5637 - loss: 0.6918 - val_accuracy: 0.4357 - val_loss: 0.6967\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5038 - loss: 0.6935 - val_accuracy: 0.4357 - val_loss: 0.6965\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.4968 - loss: 0.6936 - val_accuracy: 0.4357 - val_loss: 0.6970\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.5191 - loss: 0.6926 - val_accuracy: 0.4357 - val_loss: 0.6985\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5342 - loss: 0.6912 - val_accuracy: 0.4357 - val_loss: 0.6998\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.5201 - loss: 0.6924 - val_accuracy: 0.4357 - val_loss: 0.6962\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4357 - val_loss: 0.6971\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5074 - loss: 0.6932 - val_accuracy: 0.4357 - val_loss: 0.6973\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.4357 - val_loss: 0.6987\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5103 - loss: 0.6931 - val_accuracy: 0.4357 - val_loss: 0.6987\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5105 - loss: 0.6933 - val_accuracy: 0.4357 - val_loss: 0.6965\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5050 - loss: 0.6931 - val_accuracy: 0.4357 - val_loss: 0.6966\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5003 - loss: 0.6936 - val_accuracy: 0.4357 - val_loss: 0.6982\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5073 - loss: 0.6929 - val_accuracy: 0.4357 - val_loss: 0.6977\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5285 - loss: 0.6918 - val_accuracy: 0.4357 - val_loss: 0.6966\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5298 - loss: 0.6922 - val_accuracy: 0.4357 - val_loss: 0.6964\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5420 - loss: 0.6917 - val_accuracy: 0.4357 - val_loss: 0.6973\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.4930 - loss: 0.6939 - val_accuracy: 0.4357 - val_loss: 0.6955\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5029 - loss: 0.6931 - val_accuracy: 0.4357 - val_loss: 0.6966\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5054 - loss: 0.6932 - val_accuracy: 0.4357 - val_loss: 0.6964\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5106 - loss: 0.6928 - val_accuracy: 0.4357 - val_loss: 0.6976\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5627 - loss: 0.6900 - val_accuracy: 0.4357 - val_loss: 0.6982\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5199 - loss: 0.6923 - val_accuracy: 0.4357 - val_loss: 0.6966\n",
      "Epoch 30/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5461 - loss: 0.6904 - val_accuracy: 0.4500 - val_loss: 0.6985\n",
      "Epoch 31/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5271 - loss: 0.6933 - val_accuracy: 0.4357 - val_loss: 0.7055\n",
      "Epoch 32/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4677 - loss: 0.7032 - val_accuracy: 0.4357 - val_loss: 0.7397\n",
      "Epoch 33/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5180 - loss: 0.7098 - val_accuracy: 0.5643 - val_loss: 0.6900\n",
      "Epoch 34/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4938 - loss: 0.6925 - val_accuracy: 0.4357 - val_loss: 0.7039\n",
      "Epoch 35/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5095 - loss: 0.6918 - val_accuracy: 0.5643 - val_loss: 0.6926\n",
      "Epoch 36/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.5044 - loss: 0.6954 - val_accuracy: 0.4357 - val_loss: 0.7008\n",
      "Epoch 37/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5458 - loss: 0.6918 - val_accuracy: 0.4357 - val_loss: 0.6997\n",
      "Epoch 38/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5204 - loss: 0.6919 - val_accuracy: 0.4357 - val_loss: 0.6949\n",
      "Epoch 39/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 0.5266 - loss: 0.6917 - val_accuracy: 0.4357 - val_loss: 0.6987\n",
      "Epoch 40/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - accuracy: 0.5065 - loss: 0.6935 - val_accuracy: 0.4357 - val_loss: 0.6943\n",
      "Epoch 41/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - accuracy: 0.5118 - loss: 0.6925 - val_accuracy: 0.4357 - val_loss: 0.6979\n",
      "Epoch 42/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - accuracy: 0.5189 - loss: 0.6926 - val_accuracy: 0.4357 - val_loss: 0.7002\n",
      "Epoch 43/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.4859 - loss: 0.6967 - val_accuracy: 0.4357 - val_loss: 0.6941\n",
      "Epoch 44/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - accuracy: 0.5227 - loss: 0.6920 - val_accuracy: 0.4357 - val_loss: 0.6978\n",
      "Epoch 45/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.5036 - loss: 0.6929 - val_accuracy: 0.4357 - val_loss: 0.6961\n",
      "Epoch 46/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step - accuracy: 0.5349 - loss: 0.6916 - val_accuracy: 0.4357 - val_loss: 0.6992\n",
      "Epoch 47/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.5427 - loss: 0.6898 - val_accuracy: 0.4357 - val_loss: 0.6961\n",
      "Epoch 48/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.5267 - loss: 0.6935 - val_accuracy: 0.4357 - val_loss: 0.6946\n",
      "Epoch 49/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.5097 - loss: 0.6927 - val_accuracy: 0.4357 - val_loss: 0.6953\n",
      "Epoch 50/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.5210 - loss: 0.6929 - val_accuracy: 0.4357 - val_loss: 0.6984\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.5296 - loss: 0.6918\n",
      "Test Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_136\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_136\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">384,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_106               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_102 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m384,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_104 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m6,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_106               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                  │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_71 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_136 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,073</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m415,073\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">415,073</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m415,073\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, LSTM\n",
    "\n",
    "cnn_lstm_model = Sequential([\n",
    "    Embedding(input_dim=6000, output_dim=64,embeddings_initializer='uniform'),\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(152, 64)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(64, dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn_lstm_model.build(input_shape=(None, 120))\n",
    "cnn_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8453 - loss: 0.3378 - val_accuracy: 0.9286 - val_loss: 0.2090\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9298 - loss: 0.2051 - val_accuracy: 0.9357 - val_loss: 0.1642\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9385 - loss: 0.1797 - val_accuracy: 0.9571 - val_loss: 0.1437\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9528 - loss: 0.1626 - val_accuracy: 0.9643 - val_loss: 0.1222\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9573 - loss: 0.1336 - val_accuracy: 0.9500 - val_loss: 0.1422\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9581 - loss: 0.1408 - val_accuracy: 0.9643 - val_loss: 0.1399\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9384 - loss: 0.1723 - val_accuracy: 0.9500 - val_loss: 0.1977\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9486 - loss: 0.1627 - val_accuracy: 0.9571 - val_loss: 0.1285\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9486 - loss: 0.1787 - val_accuracy: 0.9143 - val_loss: 0.2312\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9330 - loss: 0.2186 - val_accuracy: 0.9571 - val_loss: 0.1376\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9597 - loss: 0.1462 - val_accuracy: 0.9643 - val_loss: 0.1182\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9530 - loss: 0.1452 - val_accuracy: 0.9571 - val_loss: 0.1250\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9469 - loss: 0.1393 - val_accuracy: 0.9714 - val_loss: 0.1171\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9688 - loss: 0.0991 - val_accuracy: 0.9286 - val_loss: 0.2255\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9299 - loss: 0.1983 - val_accuracy: 0.9571 - val_loss: 0.1390\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9507 - loss: 0.1309 - val_accuracy: 0.9571 - val_loss: 0.1174\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9592 - loss: 0.1126 - val_accuracy: 0.9643 - val_loss: 0.1090\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9745 - loss: 0.0890 - val_accuracy: 0.9643 - val_loss: 0.1115\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9715 - loss: 0.0841 - val_accuracy: 0.9643 - val_loss: 0.1327\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9701 - loss: 0.0917 - val_accuracy: 0.9714 - val_loss: 0.1102\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9644 - loss: 0.0893 - val_accuracy: 0.9714 - val_loss: 0.1130\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9806 - loss: 0.0643 - val_accuracy: 0.9714 - val_loss: 0.1053\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9712 - loss: 0.0830 - val_accuracy: 0.9643 - val_loss: 0.1207\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9706 - loss: 0.1116 - val_accuracy: 0.9714 - val_loss: 0.1000\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9709 - loss: 0.0811 - val_accuracy: 0.9714 - val_loss: 0.0938\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9661 - loss: 0.1109 - val_accuracy: 0.9714 - val_loss: 0.0909\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9748 - loss: 0.0821 - val_accuracy: 0.9714 - val_loss: 0.0859\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9678 - loss: 0.1031 - val_accuracy: 0.9643 - val_loss: 0.1078\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9677 - loss: 0.0983 - val_accuracy: 0.9714 - val_loss: 0.1016\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9709 - loss: 0.1005 - val_accuracy: 0.9786 - val_loss: 0.0978\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9702 - loss: 0.0855 - val_accuracy: 0.9714 - val_loss: 0.0887\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9772 - loss: 0.0791 - val_accuracy: 0.9714 - val_loss: 0.1036\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9748 - loss: 0.0869 - val_accuracy: 0.9786 - val_loss: 0.0890\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9723 - loss: 0.0881 - val_accuracy: 0.9786 - val_loss: 0.0887\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9717 - loss: 0.0966 - val_accuracy: 0.9786 - val_loss: 0.1017\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9651 - loss: 0.1184 - val_accuracy: 0.9786 - val_loss: 0.0794\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9807 - loss: 0.0645 - val_accuracy: 0.9786 - val_loss: 0.0787\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9751 - loss: 0.0741 - val_accuracy: 0.9714 - val_loss: 0.0805\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9908 - loss: 0.0419 - val_accuracy: 0.9786 - val_loss: 0.0836\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9807 - loss: 0.0673 - val_accuracy: 0.9714 - val_loss: 0.0827\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9716 - loss: 0.0765 - val_accuracy: 0.9786 - val_loss: 0.0845\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9792 - loss: 0.0631 - val_accuracy: 0.9786 - val_loss: 0.0916\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9808 - loss: 0.0631 - val_accuracy: 0.9714 - val_loss: 0.0934\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9729 - loss: 0.0915 - val_accuracy: 0.9786 - val_loss: 0.0803\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9785 - loss: 0.0679 - val_accuracy: 0.9714 - val_loss: 0.1333\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9756 - loss: 0.0675 - val_accuracy: 0.9714 - val_loss: 0.0924\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9675 - loss: 0.0930 - val_accuracy: 0.9857 - val_loss: 0.0764\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9872 - loss: 0.0437 - val_accuracy: 0.9643 - val_loss: 0.1388\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9756 - loss: 0.0742 - val_accuracy: 0.9714 - val_loss: 0.0797\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9845 - loss: 0.0548 - val_accuracy: 0.9786 - val_loss: 0.0769\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9051 - loss: 0.3101\n",
      "Test Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "cnn_lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_train[:len(X_train)//5], y_train[:len(y_train)//5]))\n",
    "\n",
    "loss, accuracy = cnn_lstm_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
